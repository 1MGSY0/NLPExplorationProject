{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6919db",
   "metadata": {},
   "source": [
    "- App B: News categorisation\n",
    "  - Traditional: TF-IDF + K-means\n",
    "  - Neural: BERT-sentence + K-means\n",
    "  - Metrics: Silhouette, Davies Bouldin, Calinski Harabasz scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdf107c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "SAMPLE_SIZE = 10000\n",
    "NUM_CLUSTERS = 8\n",
    "MAX_DOCS_FOR_METRICS = 3000  \n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)      # remove URLs\n",
    "    text = re.sub(r\"\\(cnn\\)\\s*--\", \"\", text)        # remove minimal CNN header\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)            # remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \" \", text)                # remove numbers\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()        # normalize whitespace\n",
    "\n",
    "    return text\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])  \n",
    "def lemmatise(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc if token.lemma_.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "115caa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'article', 'highlights'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trainAll_df = pd.read_csv(\"../../data/Dataset2/train.csv\")\n",
    "\n",
    "print(trainAll_df.columns)\n",
    "trainAll_df.head()\n",
    "\n",
    "train_df = trainAll_df.sample(n=SAMPLE_SIZE, random_state=RANDOM_SEED).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df7923bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text... this may take a few minutes.\n",
      "                                             article  \\\n",
      "0  By . Mia De Graaf . Britons flocked to beaches...   \n",
      "1  A couple who weighed a combined 32st were sham...   \n",
      "2  Video footage shows the heart stopping moment ...   \n",
      "3  Istanbul, Turkey (CNN) -- About 250 people rac...   \n",
      "4  By . Daily Mail Reporter . PUBLISHED: . 12:53 ...   \n",
      "\n",
      "                                       clean_article  \n",
      "0  by mia de graaf britons flocked to beaches acr...  \n",
      "1  a couple who weighed a combined st were shamed...  \n",
      "2  video footage shows the heart stopping moment ...  \n",
      "3  istanbul turkey about people raced across the ...  \n",
      "4  by daily mail reporter published est january u...  \n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing text... this may take a few minutes.\")\n",
    "\n",
    "train_df['clean_article'] = train_df['article'].apply(preprocess)\n",
    "\n",
    "print(train_df[['article', 'clean_article']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd47c74",
   "metadata": {},
   "source": [
    "Traditional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a01e4425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TF-IDF vectorizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesse Tham\\Desktop\\School Materials\\Year 4 Sem 1\\EE6405 Final Project\\NLPExplorationProject\\.venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jesse Tham\\Desktop\\School Materials\\Year 4 Sem 1\\EE6405 Final Project\\NLPExplorationProject\\.venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['I', 'far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature shape: (10000, 10000)\n",
      "Fitting KMeans on TF-IDF features...\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF w stop-word removal & lemmantization\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=lemmatise,\n",
    "    max_features=10000,\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "print(\"Fitting TF-IDF vectorizer...\")\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(train_df['clean_article'])\n",
    "\n",
    "print(\"TF-IDF feature shape:\", tfidf_features.shape)\n",
    "\n",
    "# K-means\n",
    "kmeans_tfidf = KMeans(\n",
    "    n_clusters=NUM_CLUSTERS,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_init=10\n",
    ")\n",
    "\n",
    "print(\"Fitting KMeans on TF-IDF features...\")\n",
    "kmeans_tfidf.fit(tfidf_features)\n",
    "\n",
    "tfidf_cluster_labels = kmeans_tfidf.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8adbc2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + KMeans metrics:\n",
      "  Silhouette score       : 0.005171798552842779\n",
      "  Davies-Bouldin index   : 9.410189114642181\n",
      "  Calinski-Harabasz index: 11.605209830411253\n"
     ]
    }
   ],
   "source": [
    "# Subsample for metrics\n",
    "num_samples_for_metrics = min(MAX_DOCS_FOR_METRICS, tfidf_features.shape[0])\n",
    "eval_indices_tfidf = np.random.choice(\n",
    "    tfidf_features.shape[0],\n",
    "    size=num_samples_for_metrics,\n",
    "    replace=False\n",
    ")\n",
    "\n",
    "tfidf_eval = tfidf_features[eval_indices_tfidf].toarray()\n",
    "tfidf_labels_eval = tfidf_cluster_labels[eval_indices_tfidf]\n",
    "\n",
    "silhouette_tfidf = silhouette_score(tfidf_eval, tfidf_labels_eval)\n",
    "davies_bouldin_tfidf = davies_bouldin_score(tfidf_eval, tfidf_labels_eval)\n",
    "calinski_harabasz_tfidf = calinski_harabasz_score(tfidf_eval, tfidf_labels_eval)\n",
    "\n",
    "print(\"TF-IDF + KMeans metrics:\")\n",
    "print(\"  Silhouette score       :\", silhouette_tfidf)\n",
    "print(\"  Davies-Bouldin index   :\", davies_bouldin_tfidf)\n",
    "print(\"  Calinski-Harabasz index:\", calinski_harabasz_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b9104",
   "metadata": {},
   "source": [
    "Neural Model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9af87952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding articles with Sentence-BERT model: all-MiniLM-L6-v2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 313/313 [11:26<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-BERT embedding shape: (10000, 384)\n",
      "Fitting KMeans on Sentence-BERT embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Sentence-BERT\n",
    "sbert_model_name = \"all-MiniLM-L6-v2\" \n",
    "sbert_model = SentenceTransformer(sbert_model_name)\n",
    "\n",
    "print(f\"Encoding articles with Sentence-BERT model: {sbert_model_name}...\")\n",
    "sbert_embeddings = sbert_model.encode(\n",
    "    train_df['clean_article'],\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True, \n",
    ")\n",
    "\n",
    "print(\"Sentence-BERT embedding shape:\", sbert_embeddings.shape)\n",
    "\n",
    "# K-means\n",
    "kmeans_sbert = KMeans(\n",
    "    n_clusters=NUM_CLUSTERS,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_init=10\n",
    ")\n",
    "\n",
    "print(\"Fitting KMeans on Sentence-BERT embeddings...\")\n",
    "kmeans_sbert.fit(sbert_embeddings)\n",
    "\n",
    "sbert_cluster_labels = kmeans_sbert.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0cf3c03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-BERT + KMeans metrics:\n",
      "  Silhouette score       : 0.03162845\n",
      "  Davies-Bouldin index   : 4.552164778063304\n",
      "  Calinski-Harabasz index: 56.79351636522212\n"
     ]
    }
   ],
   "source": [
    "num_samples_for_metrics_sbert = min(MAX_DOCS_FOR_METRICS, sbert_embeddings.shape[0])\n",
    "eval_indices_sbert = np.random.choice(\n",
    "    sbert_embeddings.shape[0],\n",
    "    size=num_samples_for_metrics_sbert,\n",
    "    replace=False\n",
    ")\n",
    "\n",
    "sbert_eval = sbert_embeddings[eval_indices_sbert]\n",
    "sbert_labels_eval = sbert_cluster_labels[eval_indices_sbert]\n",
    "\n",
    "silhouette_sbert = silhouette_score(sbert_eval, sbert_labels_eval)\n",
    "davies_bouldin_sbert = davies_bouldin_score(sbert_eval, sbert_labels_eval)\n",
    "calinski_harabasz_sbert = calinski_harabasz_score(sbert_eval, sbert_labels_eval)\n",
    "\n",
    "print(\"Sentence-BERT + KMeans metrics:\")\n",
    "print(\"  Silhouette score       :\", silhouette_sbert)\n",
    "print(\"  Davies-Bouldin index   :\", davies_bouldin_sbert)\n",
    "print(\"  Calinski-Harabasz index:\", calinski_harabasz_sbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c776c1",
   "metadata": {},
   "source": [
    "Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f2906b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Silhouette</th>\n",
       "      <th>Davies_Bouldin</th>\n",
       "      <th>Calinski_Harabasz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF + KMeans</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>9.410189</td>\n",
       "      <td>11.605210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence-BERT + KMeans</td>\n",
       "      <td>0.031628</td>\n",
       "      <td>4.552165</td>\n",
       "      <td>56.793516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Silhouette  Davies_Bouldin  Calinski_Harabasz\n",
       "0         TF-IDF + KMeans    0.005172        9.410189          11.605210\n",
       "1  Sentence-BERT + KMeans    0.031628        4.552165          56.793516"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_comparison_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\"TF-IDF + KMeans\", \"Sentence-BERT + KMeans\"],\n",
    "        \"Silhouette\": [silhouette_tfidf, silhouette_sbert],\n",
    "        \"Davies_Bouldin\": [davies_bouldin_tfidf, davies_bouldin_sbert],\n",
    "        \"Calinski_Harabasz\": [calinski_harabasz_tfidf, calinski_harabasz_sbert],\n",
    "    }\n",
    ")\n",
    "\n",
    "metrics_comparison_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
