{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Occupation Classification\n",
    "  - Traditional: Logistic Regression (TF-IDF)\n",
    "  - Neural: Fine-tuned BERT/RoBERTa\n",
    "  - Metrics: Accuracy, Precision, Recall, F1"
   ],
   "id": "bd514dd491b2b1d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Loading",
   "id": "3c9d4b9024489bc5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-12T05:31:18.823030Z",
     "start_time": "2025-11-12T05:31:18.449025Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../../data/dataset3/ted_talks_en.csv')\n",
    "data = data[['occupations', 'transcript']].dropna().reset_index(drop=True)\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                     occupations   \n",
       "0                      {0: ['climate advocate']}  \\\n",
       "1  {0: ['global health expert; data visionary']}   \n",
       "2                  {0: ['technology columnist']}   \n",
       "3    {0: ['activist for environmental justice']}   \n",
       "4                    {0: ['author', 'educator']}   \n",
       "\n",
       "                                          transcript  \n",
       "0  Thank you so much, Chris. And it's truly a gre...  \n",
       "1  About 10 years ago, I took on the task to teac...  \n",
       "2  (Music: \"The Sound of Silence,\" Simon & Garfun...  \n",
       "3  If you're here today — and I'm very happy that...  \n",
       "4  Good morning. How are you? (Audience) Good. It...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupations</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{0: ['climate advocate']}</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{0: ['global health expert; data visionary']}</td>\n",
       "      <td>About 10 years ago, I took on the task to teac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{0: ['technology columnist']}</td>\n",
       "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{0: ['activist for environmental justice']}</td>\n",
       "      <td>If you're here today — and I'm very happy that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{0: ['author', 'educator']}</td>\n",
       "      <td>Good morning. How are you? (Audience) Good. It...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Preprocessing",
   "id": "a9707db04489ffbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T07:23:36.012395Z",
     "start_time": "2025-11-12T07:23:34.987470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import re\n",
    "\n",
    "clean_data = data.copy()\n",
    "\n",
    "# extract only occupations of the main speaker\n",
    "def extract_first_occupation(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return [str(x[0])] if x else []\n",
    "    if not isinstance(x, str):\n",
    "        return []\n",
    "    s = x.strip()\n",
    "    # try to parse as literal\n",
    "    try:\n",
    "        val = ast.literal_eval(s)\n",
    "        if isinstance(val, dict):\n",
    "            first_val = next(iter(val.values()))\n",
    "            if isinstance(first_val, (list, tuple)):\n",
    "                return [str(first_val[0])] if first_val else []\n",
    "            return [str(first_val).split(',')[0].strip()] if first_val else []\n",
    "        if isinstance(val, (list, tuple)):\n",
    "            return [str(val[0])] if val else []\n",
    "        if isinstance(val, str):\n",
    "            return [val.split(',')[0].strip()]\n",
    "    except Exception:\n",
    "        pass\n",
    "    # fallback: check for brackets\n",
    "    m = re.search(r'\\[(.*?)\\]', s)\n",
    "    if m:\n",
    "        inside = m.group(1)\n",
    "        parts = [p.strip().strip('\\'\"') for p in re.split(r',\\s*', inside) if p.strip()]\n",
    "        return [parts[0]] if parts else []\n",
    "    # fallback: split by comma\n",
    "    parts = [p.strip().strip('\\'\"') for p in re.split(r',\\s*', s) if p.strip()]\n",
    "    return [parts[0]] if parts else []\n",
    "\n",
    "PATTERNS = {\n",
    "    'author': ['author', 'writer', 'novelist', 'biographer', 'poet'],\n",
    "    'researcher': ['researcher', 'scientist', 'research', 'physicist', 'chemist', 'biologist'],\n",
    "    'academic': ['professor', 'lecturer', 'associate professor', 'assistant professor', 'academic'],\n",
    "    'engineer': ['engineer', 'developer', 'programmer', 'software', 'architect'],\n",
    "    'entrepreneur': ['entrepreneur', 'founder', 'ceo', 'co-founder', 'startup'],\n",
    "    'artist': ['artist', 'painter', 'sculptor', 'illustrator', 'designer'],\n",
    "    'musician': ['musician', 'composer', 'singer', 'songwriter'],\n",
    "    'actor': ['actor', 'actress', 'performer'],\n",
    "    'journalist': ['journalist', 'reporter', 'editor'],\n",
    "    'politician': ['politician', 'minister', 'senator', 'mayor'],\n",
    "}\n",
    "\n",
    "def map_to_coarse(label: str) -> str:\n",
    "    if not isinstance(label, str) or not label.strip():\n",
    "        return 'other'\n",
    "    s = label.lower()\n",
    "    # remove common modifiers\n",
    "    s = re.sub(r'(\\baward[-\\s]?winning\\b|\\bbest[-\\s]?selling\\b|\\bformer\\b|\\bsenior\\b|\\bchief\\b|\\blead\\b)', ' ', s)\n",
    "    s = re.sub(r'[^a-z0-9\\s]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    # check patterns\n",
    "    for coarse, kws in PATTERNS.items():\n",
    "        for kw in kws:\n",
    "            if kw in s:\n",
    "                return coarse\n",
    "    # fallback: use last word as coarse label\n",
    "    parts = s.split()\n",
    "    return parts[-1] if parts else 'other'\n",
    "\n",
    "clean_data['occupations'] = clean_data['occupations'].apply(extract_first_occupation)\n",
    "\n",
    "# Remove entries with empty occupations\n",
    "clean_data = clean_data[clean_data['occupations'].map(lambda x: bool(x))].reset_index(drop=True)\n",
    "\n",
    "clean_data['transcript'] = clean_data['transcript'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "clean_data['transcript'] = clean_data['transcript'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "clean_data['occupations'] = clean_data['occupations'].map(\n",
    "    lambda lst: [map_to_coarse(lst[0])] if lst else []\n",
    ")\n",
    "top_k = 30\n",
    "counts = clean_data['occupations'].explode().value_counts()\n",
    "top_labels = set(counts.nlargest(top_k).index.tolist())\n",
    "\n",
    "def keep_top_or_other(lst):\n",
    "    if not lst:\n",
    "        return ['other']\n",
    "    lab = lst[0]\n",
    "    return [lab] if lab in top_labels else ['other']\n",
    "\n",
    "clean_data['occupations'] = clean_data['occupations'].map(keep_top_or_other)\n",
    "clean_data = clean_data[clean_data['occupations'].map(bool)].reset_index(drop=True)\n",
    "print(\"Coarse occupation counts:\\n\", clean_data['occupations'].explode().value_counts())\n",
    "\n",
    "train_data, test_data = train_test_split(clean_data, test_size=0.2, random_state=63)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "print(f\"Train size: {len(train_data)}, Test size: {len(test_data)}\")\n",
    "print(clean_data.head())\n"
   ],
   "id": "392635e51d8fb435",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse occupation counts:\n",
      " occupations\n",
      "other             1072\n",
      "researcher         466\n",
      "author             289\n",
      "artist             255\n",
      "entrepreneur       160\n",
      "engineer           144\n",
      "journalist         129\n",
      "activist           120\n",
      "expert              98\n",
      "psychologist        71\n",
      "economist           63\n",
      "advocate            54\n",
      "inventor            50\n",
      "educator            48\n",
      "musician            43\n",
      "photographer        38\n",
      "academic            33\n",
      "technologist        31\n",
      "philosopher         30\n",
      "filmmaker           28\n",
      "visionary           28\n",
      "physician           25\n",
      "scholar             25\n",
      "politician          24\n",
      "actor               24\n",
      "consultant          24\n",
      "roboticist          23\n",
      "theorist            23\n",
      "strategist          22\n",
      "anthropologist      22\n",
      "historian           21\n",
      "Name: count, dtype: int64\n",
      "Train size: 2786, Test size: 697\n",
      "   occupations                                         transcript\n",
      "0   [advocate]  Thank you so much, Chris. And it's truly a gre...\n",
      "1  [visionary]  About 10 years ago, I took on the task to teac...\n",
      "2      [other]  (Music: \"The Sound of Silence,\" Simon & Garfun...\n",
      "3      [other]  If you're here today — and I'm very happy that...\n",
      "4     [author]  Good morning. How are you? (Audience) Good. It...\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Traditional Model: Logistic Regression with TF-IDF",
   "id": "a2198e68b4a4b9fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T07:24:15.591070Z",
     "start_time": "2025-11-12T07:24:03.946160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "multi_target_log_reg = MultiOutputClassifier(log_reg)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('clf', multi_target_log_reg)\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "mlb = MultiLabelBinarizer()\n",
    "X_train = train_data['transcript']\n",
    "y_train = mlb.fit_transform(train_data['occupations'])    # fit on train\n",
    "X_test = test_data['transcript']\n",
    "y_test = mlb.transform(test_data['occupations'])          # transform test to same columns\n",
    "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_, zero_division=0))"
   ],
   "id": "92fb1133bc33ee57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (2786, 31), y_test shape: (697, 31)\n",
      "Logistic Regression Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      academic       0.00      0.00      0.00         7\n",
      "      activist       0.00      0.00      0.00        29\n",
      "         actor       0.00      0.00      0.00         3\n",
      "      advocate       0.00      0.00      0.00         6\n",
      "anthropologist       0.00      0.00      0.00         4\n",
      "        artist       0.00      0.00      0.00        42\n",
      "        author       0.00      0.00      0.00        56\n",
      "    consultant       0.00      0.00      0.00         7\n",
      "     economist       0.00      0.00      0.00        14\n",
      "      educator       0.00      0.00      0.00        10\n",
      "      engineer       0.00      0.00      0.00        24\n",
      "  entrepreneur       0.00      0.00      0.00        37\n",
      "        expert       0.00      0.00      0.00        14\n",
      "     filmmaker       0.00      0.00      0.00         5\n",
      "     historian       0.00      0.00      0.00         6\n",
      "      inventor       0.00      0.00      0.00        10\n",
      "    journalist       0.00      0.00      0.00        28\n",
      "      musician       0.00      0.00      0.00         7\n",
      "         other       1.00      0.04      0.08       203\n",
      "   philosopher       0.00      0.00      0.00         5\n",
      "  photographer       0.00      0.00      0.00        10\n",
      "     physician       0.00      0.00      0.00         7\n",
      "    politician       0.00      0.00      0.00         5\n",
      "  psychologist       0.00      0.00      0.00        14\n",
      "    researcher       1.00      0.03      0.06       105\n",
      "    roboticist       0.00      0.00      0.00         7\n",
      "       scholar       0.00      0.00      0.00         7\n",
      "    strategist       0.00      0.00      0.00         7\n",
      "  technologist       0.00      0.00      0.00         9\n",
      "      theorist       0.00      0.00      0.00         3\n",
      "     visionary       0.00      0.00      0.00         6\n",
      "\n",
      "     micro avg       1.00      0.02      0.03       697\n",
      "     macro avg       0.06      0.00      0.00       697\n",
      "  weighted avg       0.44      0.02      0.03       697\n",
      "   samples avg       0.02      0.02      0.02       697\n",
      "\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d83fa4ebdb7d8904"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
